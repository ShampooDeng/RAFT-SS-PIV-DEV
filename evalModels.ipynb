{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this notebok is deprecated, see evaluateModels.py instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "from RAFT.flowNetsRAFT256_SS import RAFT256_SS\n",
    "from RAFT.flowNetsRAFT256 import RAFT256\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.utils import flow_to_image\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 0)\n",
    "# _ = torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-n', '--nodes', default=1, type=int,\n",
    "                    help='number of compute nodes')\n",
    "parser.add_argument('-g', '--gpus', default=2, type=int,\n",
    "                    help='number of gpus per node')\n",
    "parser.add_argument('--name', type=str, default='RAFT-PIV256_test_test1',\n",
    "                    help='name of experiment')\n",
    "parser.add_argument('--input_path_ckpt', type=str,\n",
    "                    default='./precomputed_ckpts/RAFT256-PIV_ProbClass2/ckpt.tar',\n",
    "                    help='path of already trained checkpoint')\n",
    "parser.add_argument('--recover', type=eval, default=True,\n",
    "                    help='Wether to load an existing checkpoint')\n",
    "parser.add_argument('--output_dir_results', type=str, default='./test_results/',\n",
    "                    help='output directory of test results')\n",
    "\n",
    "parser.add_argument('--test_dataset', type=str, default='cylinder',\n",
    "                    choices=['backstep', 'cylinder', 'jhtdb', 'dns_turb', 'sqg', 'tbl', 'twcf'],\n",
    "                    help='test dataset to evaluate')\n",
    "parser.add_argument('--plot_results', type=eval, default=True,\n",
    "                    help=\"\"\"Whether or not to plot predicted results.\"\"\")\n",
    "\n",
    "parser.add_argument('--amp', type=eval, default=False, help='Wether to use auto mixed precision')\n",
    "parser.add_argument('-a', '--arch', type=str, default='RAFT256', choices=['RAFT256'],\n",
    "                    help='Type of architecture to use')\n",
    "parser.add_argument('--batch_size', default=5, type=int)\n",
    "parser.add_argument('--batch_size_test', default=1, type=int)\n",
    "parser.add_argument('--split_size', default=1, type=int)\n",
    "parser.add_argument('--offset', default=256, type=int,\n",
    "                    help='interrogation window size')\n",
    "parser.add_argument('--shift', default=64, type=int,\n",
    "                    help='shift of interrogation window in px')\n",
    "\n",
    "parser.add_argument('--iters', default=16, type=int,\n",
    "                    help='number of update steps in ConvGRU')\n",
    "parser.add_argument('--upsample', type=str, default='convex',\n",
    "                    choices=['convex', 'bicubic', 'bicubic8', 'lanczos4', 'lanczos4_8'],\n",
    "                    help=\"\"\"Type of upsampling method\"\"\")\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./PIG/oseen_100.0.npz',\n",
       " './PIG/oseen_250.0.npz',\n",
       " './PIG/oseen_500.0.npz',\n",
       " './PIG/oseen_1000.0.npz',\n",
       " './PIG/oseen_2000.0.npz',\n",
       " './PIG/oseen_3000.0.npz',\n",
       " './PIG/oseen_4000.0.npz',\n",
       " './PIG/oseen_5000.0.npz',\n",
       " './PIG/oseen_6000.0.npz',\n",
       " './PIG/oseen_7000.0.npz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = './PIG/'\n",
    "# lamb-oseen flow\n",
    "pathList = glob.glob(prefix+'oseen*.npz')\n",
    "pathList.sort(key=lambda item: float(item[12:17]))\n",
    "## sine flow\n",
    "# pathList = glob.glob('sin*.npz',root_dir='./PIG')\n",
    "# pathList.sort(key=lambda item: float(item[4:6]))\n",
    "pathList\n",
    "# [prefix + x for x in pathList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEPE(gt:torch.Tensor, pred:torch.Tensor):\n",
    "    \"\"\" gt: NxCxWxH or CxWxH\n",
    "        pred: NxCxWxH or CxWxH\n",
    "        return: float64 \"\"\"\n",
    "    if len(pred.shape) == 4:\n",
    "        pred = pred.squeeze(0)\n",
    "    if len(gt.shape) == 4:\n",
    "        gt = gt.squeeze(0)\n",
    "\n",
    "    epe = torch.sum(torch.square(pred-gt),dim=0).sqrt()\n",
    "    return epe.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./PIG/oseen_100.0.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanxuan/miniconda3/envs/torch-cupy/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402374358/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.027963761240243912, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.027966082096099854, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_250.0.npz\n",
      "tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.040658604353666306, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.040407922118902206, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_500.0.npz\n",
      "tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.06032513454556465, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.1894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.06011894345283508, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_1000.0.npz\n",
      "tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.09502723813056946, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.09601718187332153, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_2000.0.npz\n",
      "tensor(0.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.17019616067409515, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.4631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.1399783343076706, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_3000.0.npz\n",
      "tensor(0.9814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.30471622943878174, '1px': 0.96795654296875, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.17583385109901428, '1px': 0.99932861328125, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_4000.0.npz\n",
      "tensor(1.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.51237952709198, '1px': 0.832763671875, '3px': 1.0, '5px': 1.0}\n",
      "tensor(0.7939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.23222306370735168, '1px': 0.994384765625, '3px': 1.0, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_5000.0.npz\n",
      "tensor(2.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.7477708458900452, '1px': 0.7364959716796875, '3px': 0.99188232421875, '5px': 1.0}\n",
      "tensor(1.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.32623034715652466, '1px': 0.9757232666015625, '3px': 0.9996490478515625, '5px': 1.0}\n",
      "---------\n",
      "./PIG/oseen_6000.0.npz\n",
      "tensor(3.1366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 1.0006191730499268, '1px': 0.6746063232421875, '3px': 0.90863037109375, '5px': 0.9984893798828125}\n",
      "tensor(1.4118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.41339588165283203, '1px': 0.9297332763671875, '3px': 0.9970703125, '5px': 0.9989776611328125}\n",
      "---------\n",
      "./PIG/oseen_7000.0.npz\n",
      "tensor(3.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 1.2060503959655762, '1px': 0.652740478515625, '3px': 0.8632354736328125, '5px': 0.9631195068359375}\n",
      "tensor(2.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.6041893362998962, '1px': 0.8359832763671875, '3px': 0.9954376220703125, '5px': 0.998504638671875}\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = RAFT256_SS(args=args).to(device)\n",
    "checkpoint = torch.load('./results/RAFT256-PIV_SS_ProbClass2/ckpt.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "for path in pathList:\n",
    "    # read flow field\n",
    "    case = path\n",
    "    # case = prefix+path\n",
    "    print(case)\n",
    "    # case = prefix+'oseen_1000.0.npz'\n",
    "    data = np.load(case)\n",
    "    element = ['img1', 'img2', 'u', 'v']\n",
    "    img1, img2, u, v = [data[x] for x in element]\n",
    "    flows = np.stack((u,v),axis=0)\n",
    "\n",
    "    img1 = torch.from_numpy(img1).float()\n",
    "    img1 = img1.repeat(1,1,1,1)\n",
    "    img2 = torch.from_numpy(img2).float()\n",
    "    img2 = img2.repeat(1,1,1,1)\n",
    "    flows = torch.from_numpy(flows).float()\n",
    "    flows = flows.unsqueeze(dim=0)\n",
    "\n",
    "    # to gpu\n",
    "    img1, img2, flows = [x.to(device) for x in [img1,img2,flows]]\n",
    "    \n",
    "    # reshape image\n",
    "    img1 = img1 / 255\n",
    "    img2 = img2 /255\n",
    "    imgs = torch.stack((img1,img2),dim=1)\n",
    "    imgs = torch.squeeze(imgs, dim=2)\n",
    "    \n",
    "    pred_flows = model(imgs, flows, args=args, evaluate=False)\n",
    "    \n",
    "    all_flow_iters = pred_flows[0]\n",
    "    predicted_flows = all_flow_iters[-1]\n",
    "    print(pred_flows[1][0], pred_flows[1][1], sep='\\n')\n",
    "\n",
    "    # vector field\n",
    "    pred_flows = model(imgs, flows, args=args, evaluate=True)\n",
    "    all_flow_iters = pred_flows[0]\n",
    "    print(pred_flows[1][0], pred_flows[1][1], sep='\\n')\n",
    "    \n",
    "    print('---------')\n",
    "\n",
    "    # gt = np.stack((u,v),axis=0)\n",
    "    # print(gt.shape)\n",
    "    # print(all_flow_iters[-1].shape)\n",
    "    # gt = torch.from_numpy(gt).to(device)\n",
    "    # epe = computeEpe(gt,all_flow_iters[-1])\n",
    "    # print(epe)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./PIG/oseen_100.0.npz\n",
      "tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.06655582785606384, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_250.0.npz\n",
      "tensor(0.2348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.07670526206493378, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_500.0.npz\n",
      "tensor(0.3435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.11152881383895874, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_1000.0.npz\n",
      "tensor(0.5021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.1623324751853943, '1px': 1.0, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_2000.0.npz\n",
      "tensor(0.6692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.218244731426239, '1px': 0.99871826171875, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_3000.0.npz\n",
      "tensor(0.9687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.3182051181793213, '1px': 0.9839935302734375, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_4000.0.npz\n",
      "tensor(1.3471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.4328188896179199, '1px': 0.91278076171875, '3px': 1.0, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_5000.0.npz\n",
      "tensor(1.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.5614500045776367, '1px': 0.8376617431640625, '3px': 0.99920654296875, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_6000.0.npz\n",
      "tensor(2.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.7780497074127197, '1px': 0.736724853515625, '3px': 0.992431640625, '5px': 1.0}\n",
      "------\n",
      "./PIG/oseen_7000.0.npz\n",
      "tensor(2.7564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "{'epe': 0.907319962978363, '1px': 0.6883544921875, '3px': 0.973541259765625, '5px': 0.99951171875}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "model= RAFT256(args=args).to(device)\n",
    "checkpoint = torch.load('./results/ckpt.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "for path in pathList:\n",
    "    # read lamb-oseen flow field\n",
    "    # case = prefix+path\n",
    "    case = path\n",
    "    print(case)\n",
    "    # case = prefix+'oseen_1000.0.npz'\n",
    "    data = np.load(case)\n",
    "    element = ['img1', 'img2', 'u', 'v']\n",
    "    img1, img2, u, v = [data[x] for x in element]\n",
    "    flows = np.stack((u,v),axis=0)\n",
    "    \n",
    "    # Query only one sample from each sample set\n",
    "    img1 = img1[0]\n",
    "    img2 = img2[0]\n",
    "    flows = flows[:,0,...]\n",
    "    # print(img1.shape, img2.shape, flows.shape)\n",
    "\n",
    "    img1 = torch.from_numpy(img1).float()\n",
    "    img1 = img1.repeat(1,1,1,1)\n",
    "    img2 = torch.from_numpy(img2).float()\n",
    "    img2 = img2.repeat(1,1,1,1)\n",
    "    flows = torch.from_numpy(flows).float()\n",
    "    flows = flows.unsqueeze(dim=0)\n",
    "\n",
    "    # to gpu\n",
    "    img1, img2, flows = [x.to(device) for x in [img1,img2,flows]]\n",
    "    \n",
    "    # reshape image\n",
    "    img1 = img1 / 255\n",
    "    img2 = img2 /255\n",
    "    imgs = torch.stack((img1,img2),dim=1)\n",
    "    imgs = torch.squeeze(imgs, dim=2)\n",
    "\n",
    "    pred_flows = model(imgs, flows, args=args)\n",
    "    all_flow_iters = pred_flows[0]\n",
    "    predicted_flows = all_flow_iters[-1]\n",
    "    print(pred_flows[1][0], pred_flows[1][1], sep='\\n')\n",
    "    \n",
    "    # SHOW_RESULTS = True\n",
    "    # if SHOW_RESULTS:\n",
    "    #     predFlow = predicted_flows.detach().cpu().numpy()\n",
    "    #     print(predFlow.shape)\n",
    "    #     plt.quiver(predFlow[0,0,...], predFlow[0,1,...])\n",
    "    #     plt.figure(figsize=(10,10))\n",
    "    #     plt.show()\n",
    "\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./PIG/oseen_100.0.npz\n",
      "epe: 0.06867652386426926\n",
      "------\n",
      "./PIG/oseen_250.0.npz\n",
      "epe: 0.08900302648544312\n",
      "------\n",
      "./PIG/oseen_500.0.npz\n",
      "epe: 0.09371756762266159\n",
      "------\n",
      "./PIG/oseen_1000.0.npz\n",
      "epe: 0.11205799132585526\n",
      "------\n",
      "./PIG/oseen_2000.0.npz\n",
      "epe: 0.1699695587158203\n",
      "------\n",
      "./PIG/oseen_3000.0.npz\n",
      "epe: 0.2768195867538452\n",
      "------\n",
      "./PIG/oseen_4000.0.npz\n",
      "epe: 0.4395485520362854\n",
      "------\n",
      "./PIG/oseen_5000.0.npz\n",
      "epe: 0.6480282545089722\n",
      "------\n",
      "./PIG/oseen_6000.0.npz\n",
      "epe: 1.142491340637207\n",
      "------\n",
      "./PIG/oseen_7000.0.npz\n",
      "epe: 1.6230933666229248\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from unliteflownet.model.models import Network, estimate\n",
    "\n",
    "model = Network().cuda(0)\n",
    "ckpt = torch.load('./results/UnLiteFlowNet-PIV_Problem2/ckpt.tar')\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "for path in pathList:\n",
    "    # read lamb-oseen flow field\n",
    "    # case = prefix+path\n",
    "    case = path\n",
    "    print(case)\n",
    "    # case = prefix+'oseen_1000.0.npz'\n",
    "    data = np.load(case)\n",
    "    element = ['img1', 'img2', 'u', 'v']\n",
    "    img1, img2, u, v = [data[x] for x in element]\n",
    "    flows = np.stack((u,v),axis=0)\n",
    "\n",
    "    img1 = torch.from_numpy(img1).float()\n",
    "    img1 = img1.repeat(1,1,1,1)\n",
    "    img2 = torch.from_numpy(img2).float()\n",
    "    img2 = img2.repeat(1,1,1,1)\n",
    "    flows = torch.from_numpy(flows).float()\n",
    "    flows = flows.unsqueeze(dim=0)\n",
    "\n",
    "    # to gpu\n",
    "    img1, img2, flows = [x.to(device) for x in [img1,img2,flows]]\n",
    "    \n",
    "    # reshape image\n",
    "    img1 = img1 / 255\n",
    "    img2 = img2 /255\n",
    "    imgs = torch.stack((img1,img2),dim=1)\n",
    "    imgs = torch.squeeze(imgs, dim=2)\n",
    "\n",
    "    # pred_flows = model(imgs, flows, args=args)\n",
    "    # all_flow_iters = pred_flows[0]\n",
    "    # predicted_flows = all_flow_iters[-1]\n",
    "    # print(pred_flows[1][0], pred_flows[1][1], sep='\\n')\n",
    "\n",
    "    output_forward = estimate(img1, img2, model, train=True)\n",
    "    # loss = criterion_val(output_forward[-1],flows)\n",
    "    # validation_EPE += loss.item()*image1.shape[0]\n",
    "    epe = computeEPE(output_forward[-1],flows)\n",
    "    print(f\"epe: {epe}\")\n",
    "\n",
    "    print('------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
